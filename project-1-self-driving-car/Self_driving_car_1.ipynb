{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XHFnthirwlfn"
   },
   "outputs": [],
   "source": [
    "# Credits: https://github.com/SullyChen/Autopilot-TensorFlow\n",
    "# Research paper: End to End Learning for Self-Driving Cars by Nvidia. [https://arxiv.org/pdf/1604.07316.pdf]\n",
    "\n",
    "# NVidia dataset: 72 hrs of video => 72*60*60*30 = 7,776,000 images\n",
    "# Nvidia blog: https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "# Our Dataset: https://github.com/SullyChen/Autopilot-TensorFlow [https://drive.google.com/file/d/0B-KJCaaF7elleG1RbzVPZWV4Tlk/view]\n",
    "# Size: 25 minutes = 25*60*30 = 45,000 images ~ 2.3 GB\n",
    "\n",
    "\n",
    "# If you want to try on a slightly large dataset: 70 minutes of data ~ 223GB\n",
    "# Refer: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5\n",
    "# Format: Image, latitude, longitude, gear, brake, throttle, steering angles and speed\n",
    "\n",
    "\n",
    "\n",
    "# Additional Installations:\n",
    "# pip3 install h5py\n",
    "\n",
    "\n",
    "# AWS: https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n",
    "\n",
    "# Youtube:https://www.youtube.com/watch?v=qhUvQiKec2U\n",
    "# Further reading and extensions: https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c\n",
    "# More data: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing data.txt\n"
     ]
    }
   ],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = './driving_dataset/'  #Folder in which data is present \n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt') #Exact path from where data is to retrieve\n",
    "\n",
    "LIMIT = None\n",
    "split =0.8    #80% of data is train-dataset,20% of data is test-dataset \n",
    "X = []\n",
    "y = []\n",
    "with open(TRAIN_FILE) as fp: #opening the file \n",
    "    for line in islice(fp, LIMIT):  \n",
    "        path, angle = line.strip().split()  #split data into path & angle (of each image)\n",
    "        full_path = os.path.join(DATA_FOLDER, path)  #storing path in X \n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )          #storing path in Y\n",
    "\n",
    "\n",
    "y = np.array(y)   #converting list into Array \n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "split_index = int(len(y)*0.8)   #parameter which decided uptu where train-dataset is there \n",
    "\n",
    "train_y = y[:split_index]   #taking first 80% data \n",
    "test_y = y[split_index:]    #taking next 20% data \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy;\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "#Drawing histogram of angles present in both train-dataset & test-dataset \n",
    "import matplotlib.pyplot as plt \n",
    "plt.hist(train_y, bins=50, density=True, color='green', histtype ='step');\n",
    "plt.hist(test_y, bins=50, density=True, color='red', histtype ='step');\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above diagram we can see that Train & Test angles are not overlapping \n",
    "#yes it can happen bcoz data may varies as we move forward \n",
    "\n",
    "#Both in test & train have very often angle zero or around zero radian bcoz often roads are straights paractically \n",
    "\n",
    "#we have converted Angle from degree to radians bcoz if we have data in degree form then angle range will increse more \n",
    "#ex: -180 t0 +180 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_MSE(MEAN):0.191127\n",
      "Test_MSE(ZERO):0.190891\n"
     ]
    }
   ],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_y)   \n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_y-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(test_y-0.0)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If y_i_hat = Mean of train angles   (y_i_hat = predicted angles)\n",
    "#MSE(Mean Square Error)= 0.19 \n",
    "\n",
    "#If y_i_hat = 0  (y_i_hat = predicted angles)\n",
    "#MSE(Mean Square Error)= 0.19 \n",
    "\n",
    "#We have same results in both cases,it is bcoz train data-set is zero-centric \n",
    "\n",
    "#We uses MSE bcoz above problem is regression problem(Input: Images ,Output : Angles which is a real Number )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "#Created two lists  \n",
    "xs = []   #Input \n",
    "ys = []   #Output \n",
    "\n",
    "#Pointers which points to the end of the previous  batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"driving_dataset/data.txt\") as f:   #open path from where we have to load data\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])  #store each image with its path \n",
    "        \n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        \n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180) #Store angle in radians \n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "#Spliting Data-set into Train & Test \n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "#We pass one  whole batch in one iteration\n",
    "#train_batch_pointer points at last of that Batch \n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i)  \n",
    "                                                % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Self_driving_car.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
